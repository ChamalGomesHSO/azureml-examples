{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscription_id = \"6560575d-fa06-4e7d-95fb-f962e74efd7a\"\n",
    "# resource_group = \"azureml-examples\"\n",
    "# workspace = \"main\"\n",
    "\n",
    "subscription_id = \"15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\"\n",
    "resource_group = \"ray\"\n",
    "workspace = \"ray\"\n",
    "\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output, PyTorchDistribution\n",
    "from azure.ai.ml.entities import ResourceConfiguration, Environment \n",
    "prep = command(\n",
    "  code='src',\n",
    "  command=\n",
    "    \"python startDask.py \"\n",
    "    \"--script prep-nyctaxi.py \"\n",
    "    \"--nyc_taxi_dataset ${{inputs.nyc_taxi_dataset}} \"\n",
    "    \"--output_folder ${{outputs.output_folder}}\",\n",
    "  inputs={\n",
    "    'nyc_taxi_dataset': Input(\n",
    "        path= 'wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/',\n",
    "        mode= 'ro_mount')},\n",
    "  outputs={\n",
    "    'output_folder':Output(\n",
    "      type= 'uri_folder')},\n",
    "  environment=Environment( \n",
    "    image= 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04',\n",
    "    conda_file= 'conda.yml'),\n",
    "  compute= 'daniel-big',\n",
    "  resources=ResourceConfiguration(instance_count=4),\n",
    "  distribution=PyTorchDistribution(),\n",
    "  experiment_name= 'dask-nyctaxi-pipeline-example',\n",
    "  description= 'This sample shows how to run a distributed DASK job on AzureML. The 24GB NYC Taxi dataset is read in CSV format by a 4 node DASK cluster, processed and then written as job output in parquet format.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = command(\n",
    "  code= 'src',\n",
    "  command=\n",
    "    \"python train-xgboost.py \"\n",
    "    \"--nyc_taxi_parquet ${{inputs.nyc_taxi_parquet}} \"\n",
    "    \"--model ${{outputs.model}} \"\n",
    "    \"--tree_method ${{inputs.tree_method}} \"\n",
    "    \"--learning_rate ${{inputs.learning_rate}} \"\n",
    "    \"--gamma ${{inputs.gamma}} \"\n",
    "    \"--max_depth ${{inputs.max_depth}} \"\n",
    "    \"--num_boost_round ${{inputs.num_boost_round}} \",\n",
    "  inputs={\n",
    "    \"nyc_taxi_parquet\": Input(\n",
    "      path='azureml:azureml_polite_loquat_c3x4fj4l4m_output_data_output_folder:1',\n",
    "      mode='ro_mount'),\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"learning_rate\": 0.3,\n",
    "    \"gamma\": 1,\n",
    "    \"max_depth\": 7,\n",
    "    \"num_boost_round\": 20,\n",
    "  },\n",
    "  outputs={\n",
    "    \"model\": Output(type='mlflow_model')\n",
    "  },\n",
    "  environment=Environment(\n",
    "    image= \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file= \"conda.yml\"),\n",
    "  compute= \"daniel-big\",\n",
    "  experiment_name= \"dask-nyctaxi-example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "test = command(\n",
    "  code=\"src\",\n",
    "  command=\n",
    "    \"cp -r ${{inputs.model_in}}/* ${{outputs.model_out}} && \"\n",
    "    \"echo testing MLFLow model && \"\n",
    "    \"mlflow models predict -m ${{outputs.model_out}} -i ${{inputs.testdata}} -t json && \"\n",
    "    \"echo && \"\n",
    "    \"cat ${{outputs.model_out}}/MLmodel\",\n",
    "  inputs={\n",
    "    \"model_in\": Input(\n",
    "      path='data/fare_predict'),\n",
    "    \"testdata\": Input(\n",
    "      path='data/data.json',\n",
    "      type='uri_file')\n",
    "  },\n",
    "  outputs={\n",
    "    \"model_out\": Output(type='mlflow_model')\n",
    "  },\n",
    "  environment=Environment(\n",
    "    image= \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file= \"conda.yml\"),\n",
    "  compute= \"cpu-cluster\",\n",
    "  experiment_name= \"dask-nyctaxi-example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>dask-nyctaxi-example</td><td>icy_spider_9cyn58zx10</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/icy_spider_9cyn58zx10?wsid=/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/ray/workspaces/ray&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "CommandJob({'parameters': {}, 'type': 'command', 'status': 'Starting', 'log_files': None, 'name': 'icy_spider_9cyn58zx10', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/azureml-examples/', 'mlflow.source.git.branch': 'danielsc/sdk-preview-demo', 'mlflow.source.git.commit': '103eb2aac7abe0a747d3657f81bc1add7297f960', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '0b46b4bf-dd7b-4afd-ac32-32398c45199f'}, 'id': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/jobs/icy_spider_9cyn58zx10', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x7f5850a90bb0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5850a909a0>, 'command': 'cp -r ${{inputs.model_in}}/* ${{outputs.model_out}} && echo testing MLFLow model && mlflow models predict -m ${{outputs.model_out}} -i ${{inputs.testdata}} -t json && echo && cat ${{outputs.model_out}}/MLmodel', 'code': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/codes/9652f5b0-08ea-4e3a-b080-ce83764fa82e/versions/1', 'environment_variables': {}, 'environment': 'CliV2AnonymousEnvironment:6ec99a9d7a3e89824128866d18eb6cd6', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'display_name': 'icy_spider_9cyn58zx10', 'experiment_name': 'dask-nyctaxi-example', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f5850a90ca0>, 'Studio': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f5850a906d0>}, 'outputs': {'model_out': {'type': 'mlflow_model', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.icy_spider_9cyn58zx10', 'mode': 'rw_mount'}}, 'inputs': {'model_in': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/9fc7413c5ff00c2a9a50881f6fd9fa4c/fare_predict/', 'mode': 'ro_mount'}, 'testdata': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/884c9eefcd53f34169fe9b2c75e2a596/data.json', 'mode': 'ro_mount'}}, 'limits': None, 'identity': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.create_or_update(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "@pipeline()\n",
    "def my_pipeline():\n",
    "    \n",
    "    return dict()\n",
    "\n",
    "nyc_raw_data = Input(path='wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/')\n",
    "\n",
    "pipeline_job = my_pipeline(input_dataset=nyc_raw_data, tree_depth=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>demo</td><td>bright_car_gd7fcd1ngf</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/bright_car_gd7fcd1ngf?wsid=/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/ray/workspaces/ray&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {'input_dataset': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7fcb41a89430>, 'tree_depth': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7fcb41a89bb0>}, 'outputs': {'model': <azure.ai.ml.entities._job.pipeline._io.PipelineOutput object at 0x7fcb41a89d90>}, 'component': _PipelineComponent({'components': {}, 'auto_increment_version': False, 'is_anonymous': True, 'name': '9baf3c31-8252-4a73-8318-0cd09d319d6f', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fcb4185faf0>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline_component', 'display_name': 'my_pipeline', 'is_deterministic': True, 'inputs': {'input_dataset': {'type': 'unknown'}, 'tree_depth': {'type': 'unknown'}}, 'outputs': {'model': {'type': 'unknown'}}, 'source': <ComponentSource.REST: 'REST'>, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] my_pipeline at 0x7fcb41a65f70>}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'bright_car_gd7fcd1ngf', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/azureml-examples/', 'mlflow.source.git.branch': 'danielsc/sdk-preview-demo', 'mlflow.source.git.commit': '103eb2aac7abe0a747d3657f81bc1add7297f960', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"tree_depth\":\"5\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/jobs/bright_car_gd7fcd1ngf', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x7fcb41853d00>, 'serialize': <msrest.serialization.Serializer object at 0x7fcb41a89a90>, 'display_name': 'my_pipeline', 'experiment_name': 'demo', 'compute': None, 'services': {'Tracking': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7fcb4185f8e0>, 'Studio': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7fcb4185f8b0>}, 'jobs': {'foo_bar_job': {}, 'train_job': {}}, 'settings': <azure.ai.ml.entities._job.pipeline.pipeline_job_settings.PipelineJobSettings object at 0x7fcb416f9e20>, 'identity': None, 'schedule': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job.\n",
    "\n",
    "ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "@pipeline()\n",
    "def prep_train_test(dataset: Input):\n",
    "  prep_job = prep(nyc_taxi_dataset=dataset)\n",
    "  train_job = train(nyc_taxi_parquet=prep_job.outputs.output_folder,\n",
    "                    tree_method='auto',\n",
    "                    learning_rate= 0.3,\n",
    "                    gamma= 1,\n",
    "                    max_depth= 7,\n",
    "                    num_boost_round= 12)\n",
    "  test_job = test(model_in=train_job.outputs.model)\n",
    "  return dict(model=test_job.outputs.model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>e2e-dask-sweep</td><td>lucid_glove_l0xqy1fx2h</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/lucid_glove_l0xqy1fx2h?wsid=/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/ray/workspaces/ray&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {'dataset': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7f584be87280>}, 'outputs': {'model': <azure.ai.ml.entities._job.pipeline._io.PipelineOutput object at 0x7f584be876d0>}, 'component': _PipelineComponent({'components': {}, 'auto_increment_version': False, 'is_anonymous': True, 'name': '2c1828d2-026e-409c-900b-0ba35e926724', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f584bbed820>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline_component', 'display_name': 'prep_train_test', 'is_deterministic': True, 'inputs': {'dataset': {'type': 'unknown'}}, 'outputs': {'model': {'type': 'unknown'}}, 'source': <ComponentSource.REST: 'REST'>, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] prep_train_test at 0x7f584bfa5940>}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'lucid_glove_l0xqy1fx2h', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/azureml-examples/', 'mlflow.source.git.branch': 'danielsc/sdk-preview-demo', 'mlflow.source.git.commit': '103eb2aac7abe0a747d3657f81bc1add7297f960', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/jobs/lucid_glove_l0xqy1fx2h', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x7f584bbf6d60>, 'serialize': <msrest.serialization.Serializer object at 0x7f584be87400>, 'display_name': 'prep_train_test', 'experiment_name': 'e2e-dask-sweep', 'compute': None, 'services': {'Tracking': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f584bbf6ee0>, 'Studio': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f584bbf6bb0>}, 'jobs': {'prep_job': {}, 'train_job': {}, 'test_job': {}}, 'settings': <azure.ai.ml.entities._job.pipeline.pipeline_job_settings.PipelineJobSettings object at 0x7f584bbf4f70>, 'identity': None, 'schedule': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_raw_data = Input(path='wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/')\n",
    "\n",
    "pipeline_job = prep_train_test(dataset=nyc_raw_data)\n",
    "\n",
    "ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standalone Sweep Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, LogUniform\n",
    "\n",
    "train_job = train(tree_method=Choice(['approx', 'hist']),\n",
    "                  learning_rate=Uniform(0, 1),\n",
    "                  gamma= Choice(range(7)),\n",
    "                  max_depth= Choice(range(4,8)),\n",
    "                  num_boost_round= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import BayesianSamplingAlgorithm\n",
    "\n",
    "sweep_job = train_job.sweep(primary_metric='test-rmse',\n",
    "                            goal='minimize',\n",
    "                            sampling_algorithm=BayesianSamplingAlgorithm(),\n",
    "                            compute='daniel-big')\n",
    "\n",
    "sweep_job.set_limits(max_concurrent_trials=5,\n",
    "                     max_total_trials=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(BadGatewayConnection) The network connectivity issue encountered for 'Microsoft.MachineLearningServices'; cannot fulfill the request.\nCode: BadGatewayConnection\nMessage: The network connectivity issue encountered for 'Microsoft.MachineLearningServices'; cannot fulfill the request.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/azureuser/localfiles/git/azureml-examples/tutorials/e2e-dask-sweep/Sweep.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31356165396362362d393563312d343833642d613065332d6231613161336230363332342f7265736f7572636547726f7570732f7261792f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f7261792f636f6d70757465732f64616e69656c736333626967/home/azureuser/localfiles/git/azureml-examples/tutorials/e2e-dask-sweep/Sweep.ipynb#ch0000020vscode-remote?line=0'>1</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mcreate_or_update(sweep_job)\n",
      "File \u001b[0;32m/anaconda/envs/dask/lib/python3.8/site-packages/azure/ai/ml/_telemetry/activity.py:230\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     dimensions\u001b[39m.\u001b[39mupdate(custom_dimensions)\n\u001b[1;32m    229\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 230\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    231\u001b[0m     activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m return_value\n",
      "File \u001b[0;32m/anaconda/envs/dask/lib/python3.8/site-packages/azure/ai/ml/_operations/job_operations.py:396\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(rest_job_resource\u001b[39m.\u001b[39mproperties, \u001b[39m\"\u001b[39m\u001b[39midentity\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    392\u001b[0m     rest_job_resource\u001b[39m.\u001b[39mproperties\u001b[39m.\u001b[39midentity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rest_job_resource\u001b[39m.\u001b[39mproperties\u001b[39m.\u001b[39midentity, UserIdentity)\n\u001b[1;32m    394\u001b[0m ):\n\u001b[1;32m    395\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_headers_with_user_aml_token(kwargs)\n\u001b[0;32m--> 396\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_2022_02_preview\u001b[39m.\u001b[39;49mcreate_or_update(\n\u001b[1;32m    397\u001b[0m     \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49mrest_job_resource\u001b[39m.\u001b[39;49mname,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m     resource_group_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_scope\u001b[39m.\u001b[39;49mresource_group_name,\n\u001b[1;32m    399\u001b[0m     workspace_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[1;32m    400\u001b[0m     body\u001b[39m=\u001b[39;49mrest_job_resource,\n\u001b[1;32m    401\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m is_local_run(result):\n\u001b[1;32m    405\u001b[0m     ws_base_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_operations\u001b[39m.\u001b[39mall_operations[\n\u001b[1;32m    406\u001b[0m         AzureMLResourceType\u001b[39m.\u001b[39mWORKSPACE\n\u001b[1;32m    407\u001b[0m     ]\u001b[39m.\u001b[39m_operation\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_base_url\n",
      "File \u001b[0;32m/anaconda/envs/dask/lib/python3.8/site-packages/azure/core/tracing/decorator.py:83\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     85\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/anaconda/envs/dask/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_jobs_operations.py:605\u001b[0m, in \u001b[0;36mJobsOperations.create_or_update\u001b[0;34m(self, resource_group_name, workspace_name, id, body, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m     map_error(status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code, response\u001b[39m=\u001b[39mresponse, error_map\u001b[39m=\u001b[39merror_map)\n\u001b[1;32m    604\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize\u001b[39m.\u001b[39mfailsafe_deserialize(_models\u001b[39m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[0;32m--> 605\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, model\u001b[39m=\u001b[39merror, error_format\u001b[39m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    608\u001b[0m     deserialized \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize(\u001b[39m'\u001b[39m\u001b[39mJobBaseData\u001b[39m\u001b[39m'\u001b[39m, pipeline_response)\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (BadGatewayConnection) The network connectivity issue encountered for 'Microsoft.MachineLearningServices'; cannot fulfill the request.\nCode: BadGatewayConnection\nMessage: The network connectivity issue encountered for 'Microsoft.MachineLearningServices'; cannot fulfill the request."
     ]
    }
   ],
   "source": [
    "ml_client.jobs.create_or_update(sweep_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep Job in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "\n",
    "@pipeline()\n",
    "def prep_sweep_test(dataset: Input):\n",
    "  prep_job = prep(nyc_taxi_dataset=dataset)\n",
    "\n",
    "  train_job = train(nyc_taxi_parquet=prep_job.outputs.output_folder,\n",
    "                    tree_method=Choice(['approx', 'hist']),\n",
    "                    learning_rate=Uniform(0, 1),\n",
    "                    gamma= Choice(range(7)),\n",
    "                    max_depth= Choice(range(4,8)),\n",
    "                    num_boost_round= 30)\n",
    "\n",
    "  sweep_job = train_job.sweep(primary_metric='test-rmse',\n",
    "                              goal='minimize',\n",
    "                              sampling_algorithm='bayesian',\n",
    "                              compute='daniel-big')\n",
    "  \n",
    "  sweep_job.early_termination = MedianStoppingPolicy()\n",
    "\n",
    "  sweep_job.set_limits(max_concurrent_trials=5,\n",
    "                      max_total_trials=100)\n",
    "\n",
    "  test_job = test(model_in=sweep_job.outputs.model)\n",
    "  return dict(model=test_job.outputs.model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "type is not a known attribute of class <class 'azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy'> and will be ignored\n",
      "type is not a known attribute of class <class 'azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy'> and will be ignored\n",
      "type is not a known attribute of class <class 'azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>e2e-dask-sweep</td><td>strong_dinner_q7yt2wp0cm</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/strong_dinner_q7yt2wp0cm?wsid=/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourcegroups/ray/workspaces/ray&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {'dataset': <azure.ai.ml.entities._job.pipeline._io.PipelineInput object at 0x7f584b47a9a0>}, 'outputs': {'model': <azure.ai.ml.entities._job.pipeline._io.PipelineOutput object at 0x7f584b47a700>}, 'component': _PipelineComponent({'components': {}, 'auto_increment_version': False, 'is_anonymous': True, 'name': 'f0b69364-6cec-445c-8dec-6a5740b3fc49', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f584b2ab280>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline_component', 'display_name': 'prep_sweep_test', 'is_deterministic': True, 'inputs': {'dataset': {'type': 'unknown'}}, 'outputs': {'model': {'type': 'unknown'}}, 'source': <ComponentSource.REST: 'REST'>, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] prep_sweep_test at 0x7f584b5d9f70>}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'strong_dinner_q7yt2wp0cm', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/azureml-examples/', 'mlflow.source.git.branch': 'danielsc/sdk-preview-demo', 'mlflow.source.git.commit': '103eb2aac7abe0a747d3657f81bc1add7297f960', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/jobs/strong_dinner_q7yt2wp0cm', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x7f584b46dca0>, 'serialize': <msrest.serialization.Serializer object at 0x7f584b47a9d0>, 'display_name': 'prep_sweep_test', 'experiment_name': 'e2e-dask-sweep', 'compute': None, 'services': {'Tracking': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f584b46d610>, 'Studio': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x7f584b46dd90>}, 'jobs': {'prep_job': {}, 'sweep_job': {'component': {}}, 'test_job': {}}, 'settings': <azure.ai.ml.entities._job.pipeline.pipeline_job_settings.PipelineJobSettings object at 0x7f584b197490>, 'identity': None, 'schedule': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_raw_data = Input(path= 'wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/')\n",
    "\n",
    "pipeline_job = prep_sweep_test(dataset=nyc_raw_data)\n",
    "\n",
    "ml_client.jobs.create_or_update(pipeline_job)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a0221ad620db5b44101e60605626aa4976a4264882d9ec8a0dbaadb96247bd9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
