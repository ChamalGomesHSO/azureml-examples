{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscription_id = \"6560575d-fa06-4e7d-95fb-f962e74efd7a\"\n",
    "# resource_group = \"azureml-examples\"\n",
    "# workspace = \"main\"\n",
    "\n",
    "subscription_id = \"15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\"\n",
    "resource_group = \"ray\"\n",
    "workspace = \"ray\"\n",
    "\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import command, Input, Output, PyTorchDistribution\n",
    "from azure.ml.entities import ResourceConfiguration, Environment \n",
    "prep = command(\n",
    "  code='src',\n",
    "  command=\n",
    "    \"python startDask.py \"\n",
    "    \"--script prep-nyctaxi.py \"\n",
    "    \"--nyc_taxi_dataset ${{inputs.nyc_taxi_dataset}} \"\n",
    "    \"--output_folder ${{outputs.output_folder}}\",\n",
    "  inputs={\n",
    "    'nyc_taxi_dataset': Input(\n",
    "        path= 'wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/',\n",
    "        mode= 'ro_mount')},\n",
    "  outputs={\n",
    "    'output_folder':Output(\n",
    "      type= 'uri_folder')},\n",
    "  environment=Environment( \n",
    "    image= 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04',\n",
    "    conda_file= 'conda.yml'),\n",
    "  compute= 'daniel-big',\n",
    "  resources=ResourceConfiguration(instance_count=4),\n",
    "  distribution=PyTorchDistribution(),\n",
    "  experiment_name= 'dask-nyctaxi-pipeline-example',\n",
    "  description= 'This sample shows how to run a distributed DASK job on AzureML. The 24GB NYC Taxi dataset is read in CSV format by a 4 node DASK cluster, processed and then written as job output in parquet format.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = command(\n",
    "  code= 'src',\n",
    "  command=\n",
    "    \"python train-xgboost.py \"\n",
    "    \"--nyc_taxi_parquet ${{inputs.nyc_taxi_parquet}} \"\n",
    "    \"--model ${{outputs.model}} \"\n",
    "    \"--tree_method ${{inputs.tree_method}} \"\n",
    "    \"--learning_rate ${{inputs.learning_rate}} \"\n",
    "    \"--gamma ${{inputs.gamma}} \"\n",
    "    \"--max_depth ${{inputs.max_depth}} \"\n",
    "    \"--num_boost_round ${{inputs.num_boost_round}} \",\n",
    "  inputs={\n",
    "    \"nyc_taxi_parquet\": Input(\n",
    "      path='azureml:azureml_polite_loquat_c3x4fj4l4m_output_data_output_folder:1',\n",
    "      mode='ro_mount'),\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"learning_rate\": 0.3,\n",
    "    \"gamma\": 1,\n",
    "    \"max_depth\": 7,\n",
    "    \"num_boost_round\": 20,\n",
    "  },\n",
    "  outputs={\n",
    "    \"model\": Output(type='mlflow_model')\n",
    "  },\n",
    "  environment=Environment(\n",
    "    image= \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file= \"conda.yml\"),\n",
    "  compute= \"daniel-big\",\n",
    "  experiment_name= \"dask-nyctaxi-example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import command, Input, Output\n",
    "from azure.ml.entities import Environment\n",
    "\n",
    "test = command(\n",
    "  code=\"src\",\n",
    "  command=\n",
    "    \"cp -r ${{inputs.model_in}}/* ${{outputs.model_out}} && \"\n",
    "    \"echo testing MLFLow model && \"\n",
    "    \"mlflow models predict -m ${{outputs.model_out}} -i ${{inputs.testdata}} -t json && \"\n",
    "    \"echo && \"\n",
    "    \"cat ${{outputs.model_out}}/MLmodel\",\n",
    "  inputs={\n",
    "    \"model_in\": Input(\n",
    "      path='data/fare_predict'),\n",
    "    \"testdata\": Input(\n",
    "      path='data/data.json',\n",
    "      type='uri_file')\n",
    "  },\n",
    "  outputs={\n",
    "    \"model_out\": Output(type='mlflow_model')\n",
    "  },\n",
    "  environment=Environment(\n",
    "    image= \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file= \"conda.yml\"),\n",
    "  compute= \"cpu-cluster\",\n",
    "  experiment_name= \"dask-nyctaxi-example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.create_or_update(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.dsl import pipeline\n",
    "\n",
    "@pipeline()\n",
    "def prep_train_test(dataset: Input):\n",
    "  prep_job = prep(nyc_taxi_dataset=dataset)\n",
    "  train_job = train(nyc_taxi_parquet=prep_job.outputs.output_folder,\n",
    "                    tree_method='auto',\n",
    "                    learning_rate= 0.3,\n",
    "                    gamma= 1,\n",
    "                    max_depth= 7,\n",
    "                    num_boost_round= 12)\n",
    "  test_job = test(model_in=train_job.outputs.model)\n",
    "  return dict(model=test_job.outputs.model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_raw_data = Input(path='wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/')\n",
    "\n",
    "pipeline_job = prep_train_test(dataset=nyc_raw_data)\n",
    "\n",
    "ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.dsl import pipeline\n",
    "from azure.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "\n",
    "@pipeline()\n",
    "def prep_sweep_test(dataset: Input):\n",
    "  prep_job = prep(nyc_taxi_dataset=dataset)\n",
    "\n",
    "  train_job = train(nyc_taxi_parquet=prep_job.outputs.output_folder,\n",
    "                    tree_method=Choice(['approx', 'hist']),\n",
    "                    learning_rate=Uniform(0, 1),\n",
    "                    gamma= Choice(range(7)),\n",
    "                    max_depth= Choice(range(4,8)),\n",
    "                    num_boost_round= 30)\n",
    "\n",
    "  sweep_job = train_job.sweep(primary_metric='test-rmse',\n",
    "                              goal='minimize',\n",
    "                              sampling_algorithm='bayesian',\n",
    "                              compute='daniel-big')\n",
    "  \n",
    "  sweep_job.early_termination = MedianStoppingPolicy()\n",
    "\n",
    "  sweep_job.set_limits(max_concurrent_trials=5,\n",
    "                      max_total_trials=100)\n",
    "\n",
    "  test_job = test(model_in=sweep_job.outputs.model)\n",
    "  return dict(model=test_job.outputs.model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_raw_data = Input(path= 'wasbs://datasets@azuremlexamples.blob.core.windows.net/nyctaxi/')\n",
    "\n",
    "pipeline_job = prep_sweep_test(dataset=nyc_raw_data)\n",
    "\n",
    "ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standalone Sweep Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.sweep import Choice, Uniform, LogUniform\n",
    "\n",
    "train_job = train(tree_method=Choice(['auto', 'exact', 'approx', 'hist']),\n",
    "                  learning_rate=Uniform(0, 1),\n",
    "                  gamma= Choice(range(7)),\n",
    "                  max_depth= Choice(range(4,8)),\n",
    "                  num_boost_round= 20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.sweep import BayesianSamplingAlgorithm\n",
    "\n",
    "sweep_job = train_job.sweep(primary_metric='test-rmse',\n",
    "                            goal='minimize',\n",
    "                            sampling_algorithm=BayesianSamplingAlgorithm(),\n",
    "                            compute='daniel-big')\n",
    "\n",
    "sweep_job.set_limits(max_concurrent_trials=5,\n",
    "                     max_total_trials=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.create_or_update(sweep_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a0221ad620db5b44101e60605626aa4976a4264882d9ec8a0dbaadb96247bd9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
