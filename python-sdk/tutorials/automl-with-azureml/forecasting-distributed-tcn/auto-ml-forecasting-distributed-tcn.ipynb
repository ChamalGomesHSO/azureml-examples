{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e84c45a",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187e16d",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "**Distributed TCN Forecasting**\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Evaluate](#Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ffa799",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates demand forecasting for Github Daily Active Users Dataset using AutoML.\n",
    "\n",
    "AutoML highlights here include using Deep Learning forecasts, Arima, Prophet,  Remote Execution and Remote Inferencing, and working with the `forecast` function. Please also look at the additional forecasting notebooks, which document lagging, rolling windows, forecast quantiles, other ways to use the forecast function, and forecaster deployment.\n",
    "\n",
    "Make sure you have executed the [configuration](../../../configuration.ipynb) before running this notebook.\n",
    "\n",
    "Notebook synopsis:\n",
    "\n",
    "1. Creating an Experiment in an existing Workspace\n",
    "2. Configuration and remote run of AutoML for a time-series model exploring Regression learners, Arima, Prophet and DNNs\n",
    "4. Evaluating the fitted model using a rolling test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ecb53d-e958-4864-b1c2-e63ceb07a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import azureml.core\n",
    "import pandas as pd\n",
    "from azureml.automl.core.featurization import FeaturizationConfig\n",
    "from azureml.core import Experiment, Workspace, Dataset\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e42d39-dbe5-410a-9e3a-194cfc67d41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using version 1.39.0 of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3019a4ba-78a1-4a45-97bf-4e4c89fd867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>ba7979f7-d040-49c9-af1a-7414402bf622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>yuzhua-rg-easts-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKU</th>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>yuzhua-rg-eastus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run History Name</th>\n",
       "      <td>automl-ojforecasting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      \n",
       "Subscription ID   ba7979f7-d040-49c9-af1a-7414402bf622\n",
       "Workspace                            yuzhua-rg-easts-2\n",
       "SKU                                              Basic\n",
       "Resource Group                        yuzhua-rg-eastus\n",
       "Location                                        eastus\n",
       "Run History Name                  automl-ojforecasting"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for the run history container in the workspace\n",
    "experiment_name = \"automl-ojforecasting\"\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output[\"Subscription ID\"] = ws.subscription_id\n",
    "output[\"Workspace\"] = ws.name\n",
    "output[\"SKU\"] = ws.sku\n",
    "output[\"Resource Group\"] = ws.resource_group\n",
    "output[\"Location\"] = ws.location\n",
    "output[\"Run History Name\"] = experiment_name\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b3792",
   "metadata": {},
   "source": [
    "### Using AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you use `AmlCompute` as your training compute resource.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a7073d-5fe6-46b1-800f-20df36a8dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "amlcompute_cluster_name = \"oj-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D12_V2\", max_nodes=12\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a532b5",
   "metadata": {},
   "source": [
    "## Data<a id=\"data\"></a>\n",
    "You are now ready to load the historical orange juice sales data. We will load the CSV file into a plain pandas DataFrame; the time column in the CSV is called _WeekStarting_, so it will be specially parsed into the datetime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b37ccb2-cac6-467a-84d6-3be68cbb97ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekStarting</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age60</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>Hincome150</th>\n",
       "      <th>Large HH</th>\n",
       "      <th>Minorities</th>\n",
       "      <th>WorkingWoman</th>\n",
       "      <th>SSTRDIST</th>\n",
       "      <th>SSTRVOL</th>\n",
       "      <th>CPDIST5</th>\n",
       "      <th>CPWVOL5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>10560</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.232865</td>\n",
       "      <td>0.248935</td>\n",
       "      <td>10.553205</td>\n",
       "      <td>0.463887</td>\n",
       "      <td>0.103953</td>\n",
       "      <td>0.114280</td>\n",
       "      <td>0.303585</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.927280</td>\n",
       "      <td>0.376927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>minute.maid</td>\n",
       "      <td>4480</td>\n",
       "      <td>0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.232865</td>\n",
       "      <td>0.248935</td>\n",
       "      <td>10.553205</td>\n",
       "      <td>0.463887</td>\n",
       "      <td>0.103953</td>\n",
       "      <td>0.114280</td>\n",
       "      <td>0.303585</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.927280</td>\n",
       "      <td>0.376927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>8256</td>\n",
       "      <td>0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.232865</td>\n",
       "      <td>0.248935</td>\n",
       "      <td>10.553205</td>\n",
       "      <td>0.463887</td>\n",
       "      <td>0.103953</td>\n",
       "      <td>0.114280</td>\n",
       "      <td>0.303585</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.927280</td>\n",
       "      <td>0.376927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>5</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.117368</td>\n",
       "      <td>0.321226</td>\n",
       "      <td>10.922371</td>\n",
       "      <td>0.535883</td>\n",
       "      <td>0.103092</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.410568</td>\n",
       "      <td>3.801998</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.600573</td>\n",
       "      <td>0.736307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-06-14</td>\n",
       "      <td>5</td>\n",
       "      <td>minute.maid</td>\n",
       "      <td>4224</td>\n",
       "      <td>0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.117368</td>\n",
       "      <td>0.321226</td>\n",
       "      <td>10.922371</td>\n",
       "      <td>0.535883</td>\n",
       "      <td>0.103092</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.410568</td>\n",
       "      <td>3.801998</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.600573</td>\n",
       "      <td>0.736307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WeekStarting  Store        Brand  Quantity  Advert  Price     Age60  \\\n",
       "0   1990-06-14      2    dominicks     10560       1   1.59  0.232865   \n",
       "1   1990-06-14      2  minute.maid      4480       0   3.17  0.232865   \n",
       "2   1990-06-14      2    tropicana      8256       0   3.87  0.232865   \n",
       "3   1990-06-14      5    dominicks      1792       1   1.59  0.117368   \n",
       "4   1990-06-14      5  minute.maid      4224       0   2.99  0.117368   \n",
       "\n",
       "    COLLEGE     INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
       "0  0.248935  10.553205    0.463887  0.103953    0.114280      0.303585   \n",
       "1  0.248935  10.553205    0.463887  0.103953    0.114280      0.303585   \n",
       "2  0.248935  10.553205    0.463887  0.103953    0.114280      0.303585   \n",
       "3  0.321226  10.922371    0.535883  0.103092    0.053875      0.410568   \n",
       "4  0.321226  10.922371    0.535883  0.103092    0.053875      0.410568   \n",
       "\n",
       "   SSTRDIST   SSTRVOL   CPDIST5   CPWVOL5  \n",
       "0  2.110122  1.142857  1.927280  0.376927  \n",
       "1  2.110122  1.142857  1.927280  0.376927  \n",
       "2  2.110122  1.142857  1.927280  0.376927  \n",
       "3  3.801998  0.681818  1.600573  0.736307  \n",
       "4  3.801998  0.681818  1.600573  0.736307  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_column_name = \"WeekStarting\"\n",
    "data = pd.read_csv(\"dominicks_OJ.csv\", parse_dates=[time_column_name])\n",
    "\n",
    "# Drop the columns 'logQuantity' as it is a leaky feature.\n",
    "data.drop(\"logQuantity\", axis=1, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90615d2e",
   "metadata": {},
   "source": [
    "Each row in the DataFrame holds a quantity of weekly sales for an OJ brand at a single store. The data also includes the sales price, a flag indicating if the OJ brand was advertised in the store that week, and some customer demographic information based on the store location. For historical reasons, the data also include the logarithm of the sales quantity. The Dominick's grocery data is commonly used to illustrate econometric modeling techniques where logarithms of quantities are generally preferred.    \n",
    "\n",
    "The task is now to build a time-series model for the _Quantity_ column. It is important to note that this dataset is comprised of many individual time-series - one for each unique combination of _Store_ and _Brand_. To distinguish the individual time-series, we define the **time_series_id_column_names** - the columns whose values determine the boundaries between time-series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc81ea81-d181-4ca7-8531-732f0d4d1f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 249 individual time-series.\n"
     ]
    }
   ],
   "source": [
    "time_series_id_column_names = [\"Store\", \"Brand\"]\n",
    "nseries = data.groupby(time_series_id_column_names).ngroups\n",
    "print(\"Data contains {0} individual time-series.\".format(nseries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec799ec",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "We now split the data into a training and a testing set for later forecast evaluation. The test set will contain the final 12 weeks of observed sales for each time-series. The splits should be stratified by series, so we use a group-by statement on the time series identifier columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef3f694-7a53-407f-a5e4-f8885e17dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_periods = 12\n",
    "\n",
    "\n",
    "def split_last_n_by_series_id(df, n):\n",
    "    \"\"\"Group df by series identifiers and split on last n rows for each group.\"\"\"\n",
    "    df_grouped = df.sort_values(time_column_name).groupby(  # Sort by ascending time\n",
    "        time_series_id_column_names, group_keys=False\n",
    "    )\n",
    "    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])\n",
    "    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])\n",
    "    return df_head, df_tail\n",
    "\n",
    "\n",
    "train, test = split_last_n_by_series_id(data, n_test_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ace05",
   "metadata": {},
   "source": [
    "### Upload data to datastore\n",
    "The [Machine Learning service workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-workspace), is paired with the storage account, which contains the default data store. We will use it to upload the train and test data and create [tabular datasets](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) for training and testing. A tabular dataset defines a series of lazily-evaluated, immutable operations to load data from the data source into tabular representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25080333-24e6-4823-8fd4-b2dfaf89dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to dataset//48ced0c5-75ba-4d42-bc36-88ce97a0a405/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to dataset//be03c8a5-902c-410d-958e-f49ec23cb6bd/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "train_dataset = TabularDatasetFactory.register_pandas_dataframe(\n",
    "    train, target=(datastore, \"dataset/\"), name=\"dominicks_OJ_train\"\n",
    ")\n",
    "test_dataset = TabularDatasetFactory.register_pandas_dataframe(\n",
    "    test, target=(datastore, \"dataset/\"), name=\"dominicks_OJ_valid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f9672e0-a905-467b-936d-70d3a06dcb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekStarting</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age60</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>Hincome150</th>\n",
       "      <th>Large HH</th>\n",
       "      <th>Minorities</th>\n",
       "      <th>WorkingWoman</th>\n",
       "      <th>SSTRDIST</th>\n",
       "      <th>SSTRVOL</th>\n",
       "      <th>CPDIST5</th>\n",
       "      <th>CPWVOL5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23962</th>\n",
       "      <td>1992-04-16</td>\n",
       "      <td>137</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>23680</td>\n",
       "      <td>0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.209602</td>\n",
       "      <td>0.528362</td>\n",
       "      <td>10.96649</td>\n",
       "      <td>0.860739</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.11325</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>6.026484</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.77253</td>\n",
       "      <td>0.333761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23963</th>\n",
       "      <td>1992-04-23</td>\n",
       "      <td>137</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>25728</td>\n",
       "      <td>0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.209602</td>\n",
       "      <td>0.528362</td>\n",
       "      <td>10.96649</td>\n",
       "      <td>0.860739</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.11325</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>6.026484</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.77253</td>\n",
       "      <td>0.333761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23964</th>\n",
       "      <td>1992-04-30</td>\n",
       "      <td>137</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>80384</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.209602</td>\n",
       "      <td>0.528362</td>\n",
       "      <td>10.96649</td>\n",
       "      <td>0.860739</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.11325</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>6.026484</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.77253</td>\n",
       "      <td>0.333761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23965</th>\n",
       "      <td>1992-05-07</td>\n",
       "      <td>137</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>30464</td>\n",
       "      <td>0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.209602</td>\n",
       "      <td>0.528362</td>\n",
       "      <td>10.96649</td>\n",
       "      <td>0.860739</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.11325</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>6.026484</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.77253</td>\n",
       "      <td>0.333761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23966</th>\n",
       "      <td>1992-05-14</td>\n",
       "      <td>137</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>27904</td>\n",
       "      <td>0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.209602</td>\n",
       "      <td>0.528362</td>\n",
       "      <td>10.96649</td>\n",
       "      <td>0.860739</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.11325</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>6.026484</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.77253</td>\n",
       "      <td>0.333761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WeekStarting  Store      Brand  Quantity  Advert  Price     Age60  \\\n",
       "23962   1992-04-16    137  tropicana     23680       0   3.19  0.209602   \n",
       "23963   1992-04-23    137  tropicana     25728       0   2.74  0.209602   \n",
       "23964   1992-04-30    137  tropicana     80384       1   2.39  0.209602   \n",
       "23965   1992-05-07    137  tropicana     30464       0   3.19  0.209602   \n",
       "23966   1992-05-14    137  tropicana     27904       0   3.19  0.209602   \n",
       "\n",
       "        COLLEGE    INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n",
       "23962  0.528362  10.96649    0.860739  0.092996     0.11325      0.330293   \n",
       "23963  0.528362  10.96649    0.860739  0.092996     0.11325      0.330293   \n",
       "23964  0.528362  10.96649    0.860739  0.092996     0.11325      0.330293   \n",
       "23965  0.528362  10.96649    0.860739  0.092996     0.11325      0.330293   \n",
       "23966  0.528362  10.96649    0.860739  0.092996     0.11325      0.330293   \n",
       "\n",
       "       SSTRDIST   SSTRVOL  CPDIST5   CPWVOL5  \n",
       "23962  6.026484  0.705882  0.77253  0.333761  \n",
       "23963  6.026484  0.705882  0.77253  0.333761  \n",
       "23964  6.026484  0.705882  0.77253  0.333761  \n",
       "23965  6.026484  0.705882  0.77253  0.333761  \n",
       "23966  6.026484  0.705882  0.77253  0.333761  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_pandas_dataframe().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533ea19",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "For forecasting tasks, AutoML uses pre-processing and estimation steps that are specific to time-series. AutoML will undertake the following pre-processing steps:\n",
    "* Detect time-series sample frequency (e.g. hourly, daily, weekly) and create new records for absent time points to make the series regular. A regular time series has a well-defined frequency and has a value at every sample point in a contiguous time span \n",
    "* Impute missing values in the target (via forward-fill) and feature columns (using median column values) \n",
    "* Create features based on time series identifiers to enable fixed effects across different series\n",
    "* Create time-based features to assist in learning seasonal patterns\n",
    "* Encode categorical variables to numeric quantities\n",
    "\n",
    "In this notebook, AutoML will train a single, regression-type model across **all** time-series in a given training set. This allows the model to generalize across related series. If you're looking for training multiple models for different time-series, please see the many-models notebook.\n",
    "\n",
    "You are almost ready to start an AutoML training job. First, we need to separate the target column from the rest of the DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfec023-2fbc-4eab-a8a4-53c88e61808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = \"Quantity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf020d5",
   "metadata": {},
   "source": [
    "### Prepare Partition Dataset for Training\n",
    "\n",
    "To enable the distributed DNN training, a partitioned dataset is needed (More details can be found [here](https://www.ups.com/track?loc=en_US&Requester=SBN&tracknum=1Z9Y057RYW55862898&AgreeToTermsAndConditions=yes&WT.z_eCTAid=ct1_eml_Tracking__ct1_eml_tra_sb_upg1&WT.z_edatesent=07082022/trackdetails). For this notebook, we use a pipeline step to partition dataset. We will create a new paritioned dataset by call `\"oj_train_partitioned\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589fd43c-1c5a-4199-afc1-48abe5246b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_dataset_name = \"oj_train_partitioned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c72b7a6",
   "metadata": {},
   "source": [
    "#### Define RunConfig for the compute\n",
    "We will also use `pandas`, `scikit-learn` and `automl`, `pyarrow` for the pipeline steps. Defining the `runconfig` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a new runconfig object\n",
    "aml_run_config = RunConfiguration()\n",
    "\n",
    "# Use the aml_compute you created above. \n",
    "aml_run_config.target = aml_compute\n",
    "\n",
    "# Enable Docker\n",
    "aml_run_config.environment.docker.enabled = True\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn'], \n",
    "    pip_packages=['azureml-[dataset]]', 'pyarrow'])\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f846a0",
   "metadata": {},
   "source": [
    "#### Build and Run the Partition Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab216ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "oj_train_partitioned = \"scripts\"\n",
    "\n",
    "partition_step = PythonScriptStep(\n",
    "    name=\"Partition Dataset\",\n",
    "    script_name=\"partition.py\", \n",
    "    arguments=[\"--partition-columns\", time_series_id_column_names,\n",
    "               \"--new-partitioned-dataset-name\", partitioned_dataset_name\n",
    "              ],\n",
    "    inputs=[train_dataset.as_named_input('raw_data')],\n",
    "    compute_target=compute_target,\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory=prepare_data_folder,\n",
    "    allow_reuse=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e78364-e52c-451f-bf8b-b4816e534c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to /dominicks_OJ_train_train/35f8f6f0-19e1-4f3a-afa5-8a4f67f2c158/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating a new dataset.\n",
      "Successfully created a new dataset.\n",
      "registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "pipeline_steps = [partition_step]\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=False)\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b37081",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b941e4",
   "metadata": {},
   "source": [
    "After this pipelien step is finished, we can retrieve this pipeline by using the following code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f459fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parititoned_dataset = Dataset.get_by_name(ws, partitioned_dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e28a5d",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate a AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n",
    "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
    "|**training_data**|Input dataset, containing both features and label column.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "|**forecasting_dnn_models_only**|The label to enable distributed featurization and training|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95182457-c874-4b5d-a103-dce2ab7e9745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Enabling distributed featurization will result in the following parameter overrides:\n",
      "\tcv_step_size\n",
      "\ttarget_lags\n",
      "\tfeature_lags\n",
      "\ttarget_rolling_window_size\n",
      "\tcv based validation settings\n"
     ]
    }
   ],
   "source": [
    "from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
    "\n",
    "forecasting_parameters = ForecastingParameters(\n",
    "    time_column_name=time_column_name,\n",
    "    forecast_horizon=n_test_periods,\n",
    "    time_series_id_column_names=time_series_id_column_names\n",
    ")\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"forecasting\",\n",
    "    primary_metric=\"normalized_root_mean_squared_error\",\n",
    "    experiment_timeout_hours=0.5,\n",
    "    training_data=parititoned_dataset,\n",
    "    label_column_name=target_column_name,\n",
    "    verbosity=logging.INFO,\n",
    "    compute_target=compute_target,\n",
    "    max_concurrent_iterations=10,\n",
    "    max_cores_per_iteration=-1,\n",
    "    enable_dnn=True,\n",
    "    enable_early_stopping=False,\n",
    "    forecasting_parameters=forecasting_parameters,\n",
    "    forecasting_dnn_models_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add65020-3b15-43a9-8693-545b7fcc3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: oj-distributed-tcn\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'oj-distributed-tcn')\n",
    "\n",
    "print('Experiment name: ' + experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543e7ec-2170-4fc3-a7bf-b6a0331e6197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Received unrecognized parameter forecasting_dnn_models_only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting remote run.\n",
      "No run_configuration provided, running on oj-cluster with default configuration\n",
      "Running on remote compute: oj-cluster\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>oj-distributed-tcn</td><td>AutoML_43760cbd-0bcd-4885-a40c-0d2c77b1b584</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_43760cbd-0bcd-4885-a40c-0d2c77b1b584?wsid=/subscriptions/ba7979f7-d040-49c9-af1a-7414402bf622/resourcegroups/yuzhua-rg-eastus/workspaces/yuzhua-rg-easts-2&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea87bc",
   "metadata": {},
   "source": [
    "Displaying the run objects gives you links to the visual tools in the Azure Portal. Go try them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e38bf",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model for Each Algorithm\n",
    "Below we select the best pipeline from our iterations. The get_output method on automl_classifier returns the best run and the fitted model for the last fit invocation. There are overloads on get_output that allow you to retrieve the best run and fitted model for any logged metric or a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10821b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_result_df\n",
    "\n",
    "summary_df = get_result_df(remote_run)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0295ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.run import Run\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "forecast_model = \"TCNForecaster\"\n",
    "if not forecast_model in summary_df[\"run_id\"]:\n",
    "    forecast_model = \"ForecastTCN\"\n",
    "\n",
    "best_dnn_run_id = summary_df[\"run_id\"][forecast_model]\n",
    "best_dnn_run = Run(experiment, best_dnn_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85657fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dnn_run.parent\n",
    "RunDetails(best_dnn_run.parent).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dnn_run\n",
    "RunDetails(best_dnn_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b2ed4",
   "metadata": {},
   "source": [
    "## Evaluate on Test Data\n",
    "\n",
    "We now use the best fitted model from the AutoML Run to make forecasts for the test set.  \n",
    "\n",
    "We always score on the original dataset whose schema matches the training set schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_experiment = Experiment(ws, experiment_name + \"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba88fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "script_folder = os.path.join(os.getcwd(), \"inference\")\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "shutil.copy(\"infer.py\", script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import run_inference\n",
    "\n",
    "test_run = run_inference(\n",
    "    test_experiment,\n",
    "    compute_target,\n",
    "    script_folder,\n",
    "    best_dnn_run,\n",
    "    test_dataset,\n",
    "    valid_dataset,\n",
    "    forecast_horizon,\n",
    "    target_column_name,\n",
    "    time_column_name,\n",
    "    freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55da929",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(test_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import run_multiple_inferences\n",
    "\n",
    "summary_df = run_multiple_inferences(\n",
    "    summary_df,\n",
    "    experiment,\n",
    "    test_experiment,\n",
    "    compute_target,\n",
    "    script_folder,\n",
    "    test_dataset,\n",
    "    valid_dataset,\n",
    "    forecast_horizon,\n",
    "    target_column_name,\n",
    "    time_column_name,\n",
    "    freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69584b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_name, run_summary in summary_df.iterrows():\n",
    "    print(run_name)\n",
    "    print(run_summary)\n",
    "    run_id = run_summary.run_id\n",
    "    test_run_id = run_summary.test_run_id\n",
    "    test_run = Run(test_experiment, test_run_id)\n",
    "    test_run.wait_for_completion()\n",
    "    test_score = test_run.get_metrics()[run_summary.primary_metric]\n",
    "    summary_df.loc[summary_df.run_id == run_id, \"Test Score\"] = test_score\n",
    "    print(\"Test Score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
