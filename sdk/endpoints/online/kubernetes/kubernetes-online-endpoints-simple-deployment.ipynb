{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and score a machine learning model by using an online endpoint \n",
    "\n",
    "Learn how to use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure. You'll begin by deploying a model on your local machine to debug any errors, and then you'll deploy and test it in Azure.\n",
    "\n",
    "For more information, see [What are Azure Machine Learning endpoints (preview)?](https://docs.microsoft.com/azure/machine-learning/concept-endpoints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* To deploy locally, you must install Docker Engine on your local computer. We highly recommend this option, so it's easier to debug issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    KubernetesOnlineEndpoint,\n",
    "    KubernetesOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [interactive authentication](https://docs.microsoft.com/python/api/azure-identity/azure.identity.interactivebrowsercredential?view=azure-python) for this tutorial. More advanced connection methods can be found [here](https://docs.microsoft.com/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter details of your AML workspace\n",
    "subscription_id = \"4aaa645c-5ae2-4ae9-a17a-84b9023bc56a\"\n",
    "resource_group = \"amlarc-doris\"\n",
    "workspace = \"doris-ws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and debug locally by using local endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "* To deploy locally, [Docker Engine](https://docs.docker.com/engine/install/) must be installed.\n",
    "* Docker Engine must be running. Docker Engine typically starts when the computer starts. If it doesn't, you can [troubleshoot Docker Engine](https://docs.docker.com/config/daemon/#start-the-daemon-manually)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create local endpoint and deployment\n",
    "\n",
    "## 2.1 Create local endpoint\n",
    "\n",
    "The goal of a local endpoint deployment is to validate and debug your code and configuration before you deploy to Azure. Local deployment has the following limitations:\n",
    "* Local endpoints *do not support* traffic rules, authentication, or probe settings.\n",
    "* Local endpoints support only one deployment per endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a local endpoint\n",
    "import datetime\n",
    "\n",
    "local_endpoint_name = \"local-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = KubernetesOnlineEndpoint(\n",
    "    name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local endpoint (local-06171732538206) .Done (0m 5s)\n",
      "Field 'mirror_traffic': This is an experimental field, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': None, 'scoring_uri': None, 'swagger_uri': None, 'name': 'local-06171732538206', 'description': 'this is a sample local endpoint', 'tags': {}, 'properties': {}, 'id': None, 'base_path': './', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001D957A26B08>, 'auth_mode': 'key', 'location': None, 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create local deployment\n",
    "\n",
    "The example contains all the files needed to deploy a model on an online endpoint. To deploy a model, you must have:\n",
    "\n",
    "* Model files (or the name and version of a model that's already registered in your workspace). In the example, we have a scikit-learn model that does regression.\n",
    "* The code that's required to score the model. In this case, we have a score.py file.\n",
    "* An environment in which your model runs. As you'll see, the environment might be a Docker image with Conda dependencies, or it might be a Dockerfile.\n",
    "* Settings to specify the instance type and scaling capacity.\n",
    "\n",
    "### Key aspects of deployment \n",
    "\n",
    "- `name` - Name of the deployment.\n",
    "- `endpoint_name` - Name of the endpoint to create the deployment under.\n",
    "- `model` - The model to use for the deployment. This value can be either a reference to an existing versioned model in the workspace or an inline model specification.\n",
    "- `environment` - The environment to use for the deployment. This value can be either a reference to an existing versioned environment in the workspace or an inline environment specification.\n",
    "- `code_configuration` - the configuration for the source code and scoring script\n",
    "    - `path`- Path to the source code directory for scoring the model\n",
    "    - `scoring_script` - Relative path to the scoring file in the source code directory\n",
    "- `instance_type` - The VM size to use for the deployment.\n",
    "- `instance_count` - The number of instances to use for the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"../model-1/model/sklearn_regression_model.pkl\")\n",
    "env = Environment(\n",
    "    conda_file=\"../model-1/environment/conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210727.v1\",\n",
    ")\n",
    "\n",
    "blue_deployment = KubernetesOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../model-1/onlinescoring\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local deployment (local-06171732538206 / blue) .\n",
      "Building Docker image from Dockerfile\n",
      "Step 1/6 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210727.v1\n",
      "........... ---> 9fab65be7722\n",
      "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
      ". ---> Running in d54dbecea4fa\n",
      " ---> 48bbb09adfd5\n",
      "Step 3/6 : WORKDIR /var/azureml-app/\n",
      " ---> Running in 0abc8c669412\n",
      " ---> 2c9db4502ac6\n",
      "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
      " ---> 039d636fa043\n",
      "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
      " ---> Running in ef0a6ecf41d2\n",
      "Collecting package metadata (repodata.json): ...working... ............done\n",
      "Solving environment: ...working... ..done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "scikit-learn-0.24.2  | 7.5 MB    | ########## | 100% .\n",
      "joblib-1.1.0         | 210 KB    | ########## | 100% \n",
      "python-3.7.12        | 57.3 MB   | ########## | 100% ...\n",
      "scipy-1.7.1          | 21.7 MB   | ########## | 100% .\n",
      "libgfortran-ng-12.1. | 23 KB     | ########## | 100% \n",
      "pip-21.2.4           | 1.1 MB    | ########## | 100% \n",
      "numpy-1.21.2         | 6.1 MB    | ########## | 100% .\n",
      "_openmp_mutex-4.5    | 23 KB     | ########## | 100% \n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \n",
      "libgcc-ng-12.1.0     | 940 KB    | ########## | 100% \n",
      "libffi-3.4.2         | 57 KB     | ########## | 100% \n",
      "ld_impl_linux-64-2.3 | 667 KB    | ########## | 100% \n",
      "libcblas-3.9.0       | 12 KB     | ########## | 100% \n",
      "setuptools-62.3.4    | 1.3 MB    | ########## | 100% \n",
      "libzlib-1.2.12       | 63 KB     | ########## | 100% \n",
      "xz-5.2.5             | 343 KB    | ########## | 100% \n",
      "libgfortran5-12.1.0  | 1.8 MB    | ########## | 100% .\n",
      "libnsl-2.0.0         | 31 KB     | ########## | 100% \n",
      "sqlite-3.38.5        | 1.5 MB    | ########## | 100% \n",
      "libgomp-12.1.0       | 459 KB    | ########## | 100% \n",
      "zlib-1.2.12          | 91 KB     | ########## | 100% \n",
      "readline-8.1.2       | 291 KB    | ########## | 100% \n",
      "threadpoolctl-3.1.0  | 18 KB     | ########## | 100% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "ca-certificates-2022 | 149 KB    | ########## | 100% \n",
      "libopenblas-0.3.20   | 10.1 MB   | ########## | 100% .\n",
      "libstdcxx-ng-12.1.0  | 4.3 MB    | ########## | 100% \n",
      "openssl-3.0.3        | 2.9 MB    | ########## | 100% \n",
      "libblas-3.9.0        | 12 KB     | ########## | 100% \n",
      "liblapack-3.9.0      | 12 KB     | ########## | 100% \n",
      "python_abi-3.7       | 4 KB      | ########## | 100% \n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \n",
      "ncurses-6.3          | 1002 KB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... .done\n",
      "Executing transaction: ...working... done\n",
      ".Installing pip dependencies: ...working... ...................Ran pip subprocess with arguments:\n",
      "['/opt/miniconda/envs/inf-conda-env/bin/python', '-m', 'pip', 'install', '-U', '-r', '/var/azureml-app/condaenv.axko2tbb.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults==1.39.0\n",
      "  Downloading azureml_defaults-1.39.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting inference-schema[numpy-support]==1.3.0\n",
      "  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\n",
      "Collecting joblib==1.0.1\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.39.0\n",
      "  Downloading azureml_dataset_runtime-1.39.0-py3-none-any.whl (3.5 kB)\n",
      "Collecting azureml-core~=1.39.0\n",
      "  Downloading azureml_core-1.39.0.post1-py3-none-any.whl (2.5 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-inference-server-http~=0.4.1\n",
      "  Downloading azureml_inference_server_http-0.4.13-py3-none-any.whl (39 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting wrapt<=1.12.1,>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages (from inference-schema[numpy-support]==1.3.0->-r /var/azureml-app/condaenv.axko2tbb.requirements.txt (line 2)) (1.21.2)\n",
      "Collecting argcomplete<2.0\n",
      "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting docker<6.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting urllib3<=1.26.7,>=1.23\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting azure-mgmt-resource<21.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting packaging<22.0,>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting msal-extensions<0.4,>=0.3.0\n",
      "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting pyopenssl<22.0.0\n",
      "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azure-mgmt-containerregistry<9.0.0,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting azure-core<1.22\n",
      "  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.18.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
      "Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-19.1.0-py3-none-any.whl (1.8 MB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting knack~=0.9.0\n",
      "  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n",
      "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\n",
      "Collecting importlib-metadata<5,>=0.23\n",
      "  Downloading importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting six>=1.11.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.1-py3-none-any.whl (26 kB)\n",
      "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep<2.28.0a,>=2.27.1a\n",
      "  Downloading azureml_dataprep-2.27.1-py3-none-any.whl (39.4 MB)\n",
      "Collecting pyarrow<4.0.0,>=0.17.0\n",
      "  Downloading pyarrow-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azureml-dataprep-rslex~=2.3.0dev0\n",
      "  Downloading azureml_dataprep_rslex-2.3.1-cp37-cp37m-manylinux1_x86_64.whl (13.6 MB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting azure-identity==1.7.0\n",
      "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting Jinja2<3.1,>=2.10.1\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting click<8.0,>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous<2.0,>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting Werkzeug<2.0,>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting opencensus-ext-azure~=1.1.0\n",
      "  Downloading opencensus_ext_azure-1.1.4-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults==1.39.0->-r /var/azureml-app/condaenv.axko2tbb.requirements.txt (line 1)) (62.3.4)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (427 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting portalocker<3,>=1.0\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.7.0-py2.py3-none-any.whl (85 kB)\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting opencensus<1.0.0,>=0.8.0\n",
      "  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\n",
      "Collecting psutil>=5.6.3\n",
      "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "Collecting opencensus-context>=0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.8.0-py2.py3-none-any.whl (164 kB)\n",
      "Collecting protobuf<5.0.0dev,>=3.15.0\n",
      "  Downloading protobuf-4.21.1-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting protobuf<5.0.0dev,>=3.15.0\n",
      "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, wrapt\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3908 sha256=7b2fce404a09f93d812cbeff76d42a58a9025cb77b6c17622079ba64077d87ea\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/2c/0b/56aba27cc60071c52f66346a1abc22ee9db8c7376549aa4910\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=9f98a00f912b16cda74945307c687b59925ad73e7eb31767cc3c64285d9c162b\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70862 sha256=df34f56c4a6a0a3c969b574997461656e1236d32db58155ba217b90348201072\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built json-logging-py fusepy wrapt\n",
      "Installing collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, certifi, requests, pyasn1, six, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, cachetools, zipp, typing-extensions, requests-oauthlib, python-dateutil, msal-extensions, isodate, googleapis-common-protos, google-auth, distro, azure-core, opencensus-context, msrest, MarkupSafe, importlib-metadata, google-api-core, dotnetcore2, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, Werkzeug, websocket-client, tabulate, pyyaml, pytz, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, Jinja2, jeepney, itsdangerous, click, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, applicationinsights, json-logging-py, configparser, azureml-inference-server-http, azureml-core, joblib, azureml-defaults\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed Jinja2-3.0.3 MarkupSafe-2.1.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.2 Werkzeug-1.0.1 adal-1.2.7 applicationinsights-0.11.10 argcomplete-1.12.3 azure-common-1.1.28 azure-core-1.21.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.1.0 azureml-core-1.39.0.post1 azureml-dataprep-2.27.1 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.3.1 azureml-dataset-runtime-1.39.0 azureml-defaults-1.39.0 azureml-inference-server-http-0.4.13 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.2 cachetools-5.2.0 certifi-2022.6.15 cffi-1.15.0 charset-normalizer-2.0.12 click-7.1.2 cloudpickle-2.1.0 configparser-3.7.4 contextlib2-21.6.0 cryptography-36.0.2 distro-1.7.0 docker-5.0.3 dotnetcore2-2.1.23 flask-1.0.3 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.8.0 googleapis-common-protos-1.56.2 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 importlib-metadata-4.11.4 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.8.0 jmespath-0.10.0 joblib-1.0.1 json-logging-py-0.2 jsonpickle-2.2.0 knack-0.9.0 msal-1.18.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 opencensus-0.9.0 opencensus-context-0.1.2 opencensus-ext-azure-1.1.4 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.3 portalocker-2.4.0 protobuf-3.20.1 psutil-5.9.1 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.12.0 pynacl-1.5.0 pyopenssl-21.0.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.1 pyyaml-6.0 requests-2.28.0 requests-oauthlib-1.3.1 rsa-4.8 six-1.16.0 tabulate-0.8.9 typing-extensions-4.2.0 urllib3-1.26.7 websocket-client-1.3.2 wrapt-1.12.1 zipp-3.8.0\n",
      "\n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate inf-conda-env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "..... ---> b6ce67e0fd05\n",
      "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
      " ---> Running in ca320ab53aa9\n",
      " ---> b6b2509168b1\n",
      "Successfully built b6b2509168b1\n",
      "Successfully tagged local-06171732538206:blue\n",
      "\n",
      "Starting up endpoint...Done (5m 21s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'local-06171732538206', 'type': 'Kubernetes', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': WindowsPath('c:/Users/jinzhong/Documents/git-repo/azureml-examples/sdk/endpoints/online/kubernetes'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001D957A88E08>, 'model': Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': '7713d7a5680d37a33a7ac52530aec294', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': WindowsPath('c:/Users/jinzhong/Documents/git-repo/azureml-examples/sdk/endpoints/online/kubernetes'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001D957A32F08>, 'version': '1', 'latest_version': None, 'path': 'C:\\\\Users\\\\jinzhong\\\\Documents\\\\git-repo\\\\azureml-examples\\\\sdk\\\\endpoints\\\\online\\\\model-1\\\\model\\\\sklearn_regression_model.pkl', 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'}), 'code_configuration': <azure.ai.ml.entities._deployment.code_configuration.CodeConfiguration object at 0x000001D957A8FF48>, 'environment': Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': WindowsPath('c:/Users/jinzhong/Documents/git-repo/azureml-examples/sdk/endpoints/online/kubernetes'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001D957A88B88>, 'version': 'f53727d1df8137354bc0f2c69d2619ee', 'latest_version': None, 'conda_file': {'name': 'model-env', 'channels': ['conda-forge'], 'dependencies': ['python=3.7', 'numpy=1.21.2', 'pip=21.2.4', 'scikit-learn=0.24.2', 'scipy=1.7.1', {'pip': ['azureml-defaults==1.39.0', 'inference-schema[numpy-support]==1.3.0', 'joblib==1.0.1']}]}, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210727.v1', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- conda-forge\\ndependencies:\\n- python=3.7\\n- numpy=1.21.2\\n- pip=21.2.4\\n- scikit-learn=0.24.2\\n- scipy=1.7.1\\n- pip:\\n  - azureml-defaults==1.39.0\\n  - inference-schema[numpy-support]==1.3.0\\n  - joblib==1.0.1\\nname: model-env\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'resources': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Verify the local deployment succeeded\n",
    "\n",
    "## 3.1 Check the status to see whether the model was deployed without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Failed', 'scoring_uri': None, 'swagger_uri': None, 'name': 'local-06171732538206', 'description': 'this is a sample local endpoint', 'tags': {}, 'properties': {}, 'id': None, 'base_path': './', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001D957A9B748>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.get(name=local_endpoint_name, local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Get logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-06-17T09:38:21,762590361+00:00 - gunicorn/run \\r\\n2022-06-17T09:38:21,765043241+00:00 - nginx/run \\r\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\r\\n2022-06-17T09:38:21,858621694+00:00 - iot-server/finish 1 0\\r\\n2022-06-17T09:38:21,860537284+00:00 - Exit code 1 is normal. Not restarting iot-server.\\r\\nDynamic Python package installation is disabled.\\r\\nStarting HTTP server\\r\\nStarting gunicorn 20.1.0\\r\\nListening at: http://127.0.0.1:31311 (30)\\r\\nUsing worker: sync\\r\\nworker timeout is set to 300\\r\\nBooting worker with pid: 64\\r\\nSPARK_HOME not set. Skipping PySpark Initialization.\\r\\nInitializing logger\\r\\n2022-06-17 09:38:22,938 | root | INFO | Starting up app insights client\\r\\nlogging socket was found. logging is available.\\r\\nlogging socket was found. logging is available.\\r\\n2022-06-17 09:38:22,941 | root | INFO | Starting up request id generator\\r\\n2022-06-17 09:38:22,941 | root | INFO | Starting up app insight hooks\\r\\n2022-06-17 09:38:22,941 | root | INFO | Invoking user\\'s init function\\r\\nInit complete\\r\\n2022-06-17 09:38:23,234 | root | INFO | Users\\'s init has completed successfully\\r\\n2022-06-17 09:38:23,237 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\r\\n2022-06-17 09:38:23,238 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\r\\n2022-06-17 09:38:23,242 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\r\\nWORKER TIMEOUT (pid:64)\\r\\nFatal Python error: Aborted\\r\\n\\r\\nCurrent thread 0x00007fd7ced97740 (most recent call first):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/workers/sync.py\", line 36 in wait\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/workers/sync.py\", line 84 in run_for_one\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/workers/sync.py\", line 125 in run\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/workers/base.py\", line 142 in init_process\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/arbiter.py\", line 589 in spawn_worker\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/arbiter.py\", line 622 in spawn_workers\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/arbiter.py\", line 551 in manage_workers\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/arbiter.py\", line 202 in run\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/app/base.py\", line 72 in run\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/app/base.py\", line 231 in run\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.7/site-packages/gunicorn/app/wsgiapp.py\", line 67 in run\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/bin/gunicorn\", line 8 in <module>\\r\\nworker timed out, killing gunicorn\\r\\nWorker exiting (pid: 64)\\r\\nShutting down: Master\\r\\nReason: Worker failed to boot.\\r\\n2022-06-17T11:00:08,638489312+00:00 - gunicorn/finish 3 0\\r\\n2022-06-17T11:00:08,640507577+00:00 - Exit code 3 is not normal. Killing image.\\r\\nERROR conda.cli.main_run:execute(34): Subprocess for \\'conda run [\\'runsvdir\\', \\'/var/runit\\']\\' command failed.  (See above for error)\\r\\n2022-06-17T11:00:08,654498618+00:00 - rsyslog/finish 0 0\\r\\n2022-06-17T11:00:08,656577372+00:00 - Exit code 0 is not normal. Restarting rsyslog.\\r\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=local_endpoint_name, local=True, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Invoke the local endpoint\n",
    "Invoke the endpoint to score the model by using the convenience command invoke and passing query parameters that are stored in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LocalEndpointInFailedStateError",
     "evalue": "Local endpoint (local-06171732538206) is in failed state. Try getting logs to debug scoring script.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLocalEndpointInFailedStateError\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1380\\3719905138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mendpoint_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_endpoint_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrequest_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../model-1/sample-request.json\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mlocal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\jinzhong\\Miniconda3\\envs\\amlv2\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mlog_activity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_name\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jinzhong\\Miniconda3\\envs\\amlv2\\lib\\site-packages\\azure\\ai\\ml\\_operations\\online_endpoint_operations.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, endpoint_name, request_file, deployment_name, input_data, params_override, local, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             return self._local_endpoint_helper.invoke(\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0mendpoint_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeployment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeployment_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             )\n\u001b[0;32m    309\u001b[0m         endpoint = self._online_operation.get(\n",
      "\u001b[1;32mc:\\Users\\jinzhong\\Miniconda3\\envs\\amlv2\\lib\\site-packages\\azure\\ai\\ml\\_operations\\_local_endpoint_helper.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, endpoint_name, data, deployment_name)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \"\"\"\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# get_scoring_uri will throw user error if there are multiple deployments and no deployment_name is specified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mscoring_uri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_docker_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scoring_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeployment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeployment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscoring_uri\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jinzhong\\Miniconda3\\envs\\amlv2\\lib\\site-packages\\azure\\ai\\ml\\_local_endpoints\\docker_client.py\u001b[0m in \u001b[0;36mget_scoring_uri\u001b[1;34m(self, endpoint_name, deployment_name)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         self._validate_container_state(\n\u001b[1;32m--> 283\u001b[1;33m             \u001b[0mendpoint_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeployment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeployment_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         )\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scoring_uri_from_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jinzhong\\Miniconda3\\envs\\amlv2\\lib\\site-packages\\azure\\ai\\ml\\_local_endpoints\\docker_client.py\u001b[0m in \u001b[0;36m_validate_container_state\u001b[1;34m(self, endpoint_name, deployment_name, container)\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_status_from_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mLocalEndpointConstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCONTAINER_EXITED\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLocalEndpointInFailedStateError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeployment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeployment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reformat_volumes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolumes_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLocalEndpointInFailedStateError\u001b[0m: Local endpoint (local-06171732538206) is in failed state. Try getting logs to debug scoring script."
     ]
    }
   ],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    request_file=\"../model-1/sample-request.json\",\n",
    "    local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Configure Kubernetes cluster for machine learning\n",
    "Next, configure Azure Kubernetes Service (AKS) and Azure Arc-enabled Kubernetes clusters for inferencing machine learning workloads.\n",
    "There're some prerequisites for below steps, you can check them [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-attach-arc-kubernetes).\n",
    "\n",
    "## 4.1 Connect an existing Kubernetes cluster to Azure Arc\n",
    "This step is optional for [AKS cluster](https://docs.microsoft.com/en-us/azure/aks/kubernetes-walkthrough).\n",
    "Follow this [guidance](https://docs.microsoft.com/en-us/azure/azure-arc/kubernetes/quickstart-connect-cluster) to connect Kubernetes clusters.\n",
    "\n",
    "## 4.2 Deploy Azure Machine Learning extension\n",
    "Depending on your network setup, Kubernetes distribution variant, and where your Kubernetes cluster is hosted (on-premises or the cloud), choose one of options to deploy the Azure Machine Learning extension and enable inferencing workloads on your Kubernetes cluster.\n",
    "Follow this [guidance](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-attach-arc-kubernetes?tabs=studio#inferencing).\n",
    "\n",
    "## 4.3 Attach Arc Cluster\n",
    "You can use Studio, Python SDK and CLI to attach Arc cluster to Machine Learning workspace.\n",
    "Below code shows the attachment of AKS that the compute type is managedClusters. For Arc connected cluster, it should be connectedClusters.\n",
    "Follow this [guidance](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-attach-arc-kubernetes?tabs=studio#attach-arc-cluster) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_compute\n",
    "\n",
    "# for arc connected cluster, the resource_id should be something like '/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.ContainerService/connectedClusters/<CLUSTER_NAME>''\n",
    "compute_params = [\n",
    "    {\"name\": \"<COMPUTE_NAME>\"},\n",
    "    {\"type\": \"kubernetes\"},\n",
    "    {\n",
    "        \"resource_id\": \"/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.ContainerService/managedClusters/<CLUSTER_NAME>\"\n",
    "    },\n",
    "]\n",
    "k8s_compute = load_compute(path=None, params_override=compute_params)\n",
    "\n",
    "# !!!bug https://msdata.visualstudio.com/Vienna/_workitems/edit/1740311\n",
    "ml_client.begin_create_or_update(k8s_compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deploy your online endpoint to Azure\n",
    "Next, deploy your online endpoint to Azure.\n",
    "\n",
    "## 5.1 Configure online endpoint\n",
    "`endpoint_name`: The name of the endpoint.\n",
    "\n",
    "`auth_mode` : Use `key` for key-based authentication. Use `aml_token` for Azure Machine Learning token-based authentication. A `key` does not expire, but `aml_token` does expire. \n",
    "\n",
    "Optionally, you can add description, tags to your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"k8s-endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = KubernetesOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    compute=\"<COMPUTE_NAME>\",\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Create the endpoint\n",
    "\n",
    "Using the `MLClient` created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Configure online deployment\n",
    "\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `KubernetesOnlineDeployment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"../model-1/model/sklearn_regression_model.pkl\")\n",
    "env = Environment(\n",
    "    conda_file=\"../model-1/environment/conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210727.v1\",\n",
    ")\n",
    "\n",
    "blue_deployment = KubernetesOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../model-1/onlinescoring\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Create the deployment\n",
    "\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.begin_create_or_update(blue_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `endpoint_name` - Name of the endpoint\n",
    "- `request_file` - File with request data\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint\n",
    "\n",
    "We will send a sample request using a [json](./model-1/sample-request.json) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "# comment this out as cluster under dev subscription can't be accessed from public internet.\n",
    "# ml_client.online_endpoints.invoke(\n",
    "#    endpoint_name=online_endpoint_name,\n",
    "#    deployment_name='blue',\n",
    "#    request_file='../model-1/sample-request.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Managing endpoints and deployments\n",
    "\n",
    "## 7.1 Get details of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Get the logs for the new deployment\n",
    "Get the logs for the green deployment and verify as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Delete the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure"
  },
  "interpreter": {
   "hash": "b831f7c8a604aeddede7b115cb54b8e5e714309581a6efc2d482e5c9d5f881a6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('amlv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
